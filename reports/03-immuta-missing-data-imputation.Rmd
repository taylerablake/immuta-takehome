---
title: "03-immuta-missing-data-imputation"
author: "Tayler Blake"
date: "January 1, 2019"
output: html_document
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, tidy = TRUE)
```

```{r setup}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r}
library(ProjectTemplate)
load.project()
```

Now that we have our model frame that we can pass to a function call to execute model fitting, we need to split the data into a training (70%) and test (30%) set via random assignment, setting the random seed to enable reproducibility:

```{r}
set.seed(666)
train_ind <- sample(1:nrow(loan_mf), size = floor(0.7*nrow(loan_mf)))

train_mf <- loan_mf[train_ind,]
test_mf <- loan_mf[-train_ind,]
rm(loan_mf)
```

Most classifiers don't seamlessly account for missing data, and this is true for random forests, so we need to fill in the `r NA`s using reasonable data-driven logic. In a normal situation, the data scientist should have access to documentation or people closely involved with data collection and should investigate the underlying mechanism responsible for the missing values so as to handle them most appropriately. In this case, we'll assume that the data are missing at random.

A naive approach to imputation is replacing missing values with the value of some summary statistic. For numeric variables, I'll replace with column medians, and for factor variables, I'll replace with the most frequent levels (breaking ties at random). This is implemented in na.roughfix:

```{r}
imputed_train_mf <- na.roughfix(train_mf)
```

To impute missing values in the test set, we'll use the same approach, but using the column medians and most frequent levels calculated using the training set:

```{r}
formula_columns <- names(imputed_unmasked_train_mf)[!(names(imputed_unmasked_train_mf) %in%
                                          c("grade", "sub_grade"))]
column_centers <- data.frame(imputed_unmasked_train_mf[,formula_columns] %>%
                                   summarize_if(is.numeric, funs(median(., na.rm = TRUE))),
                             imputed_unmasked_train_mf[,formula_columns] %>%
                                   summarize_if(is.factor,
                                                funs(names(table(.))[which.max(table(.))]))) %>%
      as_tibble()
column_centers <- column_centers[,match(names(train_mf[, formula_columns]),
                                        names(column_centers))]
imputed_test_mf <- test_na_roughfix(formula_columns, column_centers, test_mf)
cache("imputed_train_mf")
cache("imputed_test_mf")
```

I've stopped here, but in a 'real-world' situation, I would probably opt to spend more time and effort on imputation. An obvious next direction for imputation follows:

- Initialize columns by imputing `r NA`s using column medians and modes.
- Fit a random forest to the imputed (complete) training data, and extract the proximity matrix from the fitted model.
- For continuous predictors, update the imputed value using the weighted average of the non-missing obervations, where the weights are the proximities.
- For categorical predictors, caculate the average proximity for each of the category levels; the imputed value is the category with the largest average proximity.
- Iterate.

Alternatively, one may normalize features to construct a distance metric, and using this metric, fill in missing values using the median of their k-nearest neighbors. An attractive transformation is based on a scaling of the empirical cumulative distribution function for numeric data, and its analogous counterpart for categorical variables. The transformation is invertible, ensuring no information, and it also uniformly distributes the data points corresponding to infrequently observed grades in the interval [0,1] for each feature. 

Each data vector can be viewed as a point in p-dimensional space, where p is the number of features. The transformation ensure that the distance between two data pointsin each dimension is comparable in that a distance of 0.4 in the the first dimension contains twice as many grade E loans as a distance of 0.2 in the second dimension. This enables better construction of distance metrics to identify loan grades that occur with low frequency, but are of great interest in identifying because of the risk that they present.

